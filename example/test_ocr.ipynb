{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0abca79d-c9f4-48ac-9694-2f247ab11e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amishor/miniconda3/envs/ocr/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\u001b[32mCreating model: ('PP-DocLayoutV2', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/amishor/.paddlex/official_models/PP-DocLayoutV2`.\u001b[0m\n",
      "E1207 01:08:32.084872   645 gpu_resources.cc:98] Mismatched GPU Architecture: The installed PaddlePaddle package was compiled for 61 70 75 80 86 89 90 ,but your current GPU is 120 Solution: Install the correct wheel package built for your GPU from the official PaddlePaddle website: https://www.paddlepaddle.org.cn/\n",
      "/home/amishor/miniconda3/envs/ocr/lib/python3.12/site-packages/paddlex/inference/pipelines/paddleocr_vl/pipeline.py:306: SyntaxWarning: invalid escape sequence '\\('\n",
      "  result_str.replace(\"\\(\", \" $ \")\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Unsupported GPU architecture",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m FORMAT_BLOCK_CONTENT = \u001b[38;5;28;01mTrue\u001b[39;00m      \u001b[38;5;66;03m# 是否格式化 block_content 为 Markdown\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# 创建一个全局的 pipeline，后面直接拿来用\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m pipeline = \u001b[43mPaddleOCRVL\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_layout_detection\u001b[49m\u001b[43m=\u001b[49m\u001b[43mUSE_LAYOUT_DETECTION\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mformat_block_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mFORMAT_BLOCK_CONTENT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mPaddleOCR-VL 初始化完成\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ocr/lib/python3.12/site-packages/paddleocr/_pipelines/paddleocr_vl.py:63\u001b[39m, in \u001b[36mPaddleOCRVL.__init__\u001b[39m\u001b[34m(self, layout_detection_model_name, layout_detection_model_dir, layout_threshold, layout_nms, layout_unclip_ratio, layout_merge_bboxes_mode, vl_rec_model_name, vl_rec_model_dir, vl_rec_backend, vl_rec_server_url, vl_rec_max_concurrency, doc_orientation_classify_model_name, doc_orientation_classify_model_dir, doc_unwarping_model_name, doc_unwarping_model_dir, use_doc_orientation_classify, use_doc_unwarping, use_layout_detection, use_chart_recognition, format_block_content, **kwargs)\u001b[39m\n\u001b[32m     60\u001b[39m params.pop(\u001b[33m\"\u001b[39m\u001b[33mkwargs\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     61\u001b[39m \u001b[38;5;28mself\u001b[39m._params = params\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ocr/lib/python3.12/site-packages/paddleocr/_pipelines/base.py:67\u001b[39m, in \u001b[36mPaddleXPipelineWrapper.__init__\u001b[39m\u001b[34m(self, paddlex_config, **common_args)\u001b[39m\n\u001b[32m     63\u001b[39m \u001b[38;5;28mself\u001b[39m._common_args = parse_common_args(\n\u001b[32m     64\u001b[39m     common_args, default_enable_hpi=_DEFAULT_ENABLE_HPI\n\u001b[32m     65\u001b[39m )\n\u001b[32m     66\u001b[39m \u001b[38;5;28mself\u001b[39m._merged_paddlex_config = \u001b[38;5;28mself\u001b[39m._get_merged_paddlex_config()\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m \u001b[38;5;28mself\u001b[39m.paddlex_pipeline = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_paddlex_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ocr/lib/python3.12/site-packages/paddleocr/_pipelines/base.py:105\u001b[39m, in \u001b[36mPaddleXPipelineWrapper._create_paddlex_pipeline\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    103\u001b[39m kwargs = prepare_common_init_args(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mself\u001b[39m._common_args)\n\u001b[32m    104\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcreate_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merged_paddlex_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m DependencyError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    107\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    108\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mA dependency error occurred during pipeline creation. Please refer to the installation documentation to ensure all required dependencies are installed.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    109\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ocr/lib/python3.12/site-packages/paddlex/inference/pipelines/__init__.py:167\u001b[39m, in \u001b[36mcreate_pipeline\u001b[39m\u001b[34m(pipeline, config, device, pp_option, use_hpip, hpi_config, *args, **kwargs)\u001b[39m\n\u001b[32m    164\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    165\u001b[39m     config.pop(\u001b[33m\"\u001b[39m\u001b[33mhpi_config\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m pipeline = \u001b[43mBasePipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpipeline_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpp_option\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpp_option\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_hpip\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_hpip\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhpi_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhpi_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m pipeline\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ocr/lib/python3.12/site-packages/paddlex/utils/deps.py:206\u001b[39m, in \u001b[36mpipeline_requires_extra.<locals>._deco.<locals>._wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    203\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(pipeline_cls.\u001b[34m__init__\u001b[39m)\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_wrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m    205\u001b[39m     require_extra(extra, obj_name=pipeline_name, alt=alt)\n\u001b[32m--> \u001b[39m\u001b[32m206\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mold_init_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ocr/lib/python3.12/site-packages/paddlex/inference/pipelines/_parallel.py:103\u001b[39m, in \u001b[36mAutoParallelSimpleInferencePipeline.__init__\u001b[39m\u001b[34m(self, config, *args, **kwargs)\u001b[39m\n\u001b[32m     97\u001b[39m         \u001b[38;5;28mself\u001b[39m._executor = MultiDeviceSimpleInferenceExecutor(\n\u001b[32m     98\u001b[39m             \u001b[38;5;28mself\u001b[39m._pipelines,\n\u001b[32m     99\u001b[39m             batch_sampler,\n\u001b[32m    100\u001b[39m             postprocess_result=\u001b[38;5;28mself\u001b[39m._postprocess_result,\n\u001b[32m    101\u001b[39m         )\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._multi_device_inference:\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m     \u001b[38;5;28mself\u001b[39m._pipeline = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_internal_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ocr/lib/python3.12/site-packages/paddlex/inference/pipelines/_parallel.py:158\u001b[39m, in \u001b[36mAutoParallelImageSimpleInferencePipeline._create_internal_pipeline\u001b[39m\u001b[34m(self, config, device)\u001b[39m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_create_internal_pipeline\u001b[39m(\u001b[38;5;28mself\u001b[39m, config, device):\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pipeline_cls\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpp_option\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpp_option\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_hpip\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43muse_hpip\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhpi_config\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhpi_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ocr/lib/python3.12/site-packages/paddlex/inference/pipelines/paddleocr_vl/pipeline.py:117\u001b[39m, in \u001b[36m_PaddleOCRVLPipeline.__init__\u001b[39m\u001b[34m(self, config, device, pp_option, use_hpip, hpi_config)\u001b[39m\n\u001b[32m    111\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    112\u001b[39m         layout_merge_bboxes_mode := layout_det_config.get(\n\u001b[32m    113\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mlayout_merge_bboxes_mode\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    114\u001b[39m         )\n\u001b[32m    115\u001b[39m     ) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    116\u001b[39m         layout_kwargs[\u001b[33m\"\u001b[39m\u001b[33mlayout_merge_bboxes_mode\u001b[39m\u001b[33m\"\u001b[39m] = layout_merge_bboxes_mode\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28mself\u001b[39m.layout_det_model = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcreate_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlayout_det_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mlayout_kwargs\u001b[49m\n\u001b[32m    119\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[38;5;28mself\u001b[39m.use_chart_recognition = config.get(\u001b[33m\"\u001b[39m\u001b[33muse_chart_recognition\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    123\u001b[39m vl_rec_config = config.get(\u001b[33m\"\u001b[39m\u001b[33mSubModules\u001b[39m\u001b[33m\"\u001b[39m, {}).get(\n\u001b[32m    124\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mVLRecognition\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    125\u001b[39m     {\u001b[33m\"\u001b[39m\u001b[33mmodel_config_error\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mconfig error for vl_rec_model!\u001b[39m\u001b[33m\"\u001b[39m},\n\u001b[32m    126\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ocr/lib/python3.12/site-packages/paddlex/inference/pipelines/base.py:106\u001b[39m, in \u001b[36mBasePipeline.create_model\u001b[39m\u001b[34m(self, config, **kwargs)\u001b[39m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    104\u001b[39m     pp_option = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m model = \u001b[43mcreate_predictor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    109\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    110\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbatch_size\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    111\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpp_option\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpp_option\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    112\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_hpip\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_hpip\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    113\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhpi_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhpi_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    114\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgenai_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgenai_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    115\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    116\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ocr/lib/python3.12/site-packages/paddlex/inference/models/__init__.py:84\u001b[39m, in \u001b[36mcreate_predictor\u001b[39m\u001b[34m(model_name, model_dir, device, pp_option, use_hpip, hpi_config, genai_config, *args, **kwargs)\u001b[39m\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     82\u001b[39m     config = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mBasePredictor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     88\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpp_option\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpp_option\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_hpip\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_hpip\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     90\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhpi_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhpi_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     91\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgenai_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgenai_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     93\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ocr/lib/python3.12/site-packages/paddlex/inference/models/object_detection/predictor.py:112\u001b[39m, in \u001b[36mDetPredictor.__init__\u001b[39m\u001b[34m(self, img_size, threshold, layout_nms, layout_unclip_ratio, layout_merge_bboxes_mode, *args, **kwargs)\u001b[39m\n\u001b[32m    110\u001b[39m \u001b[38;5;28mself\u001b[39m.layout_unclip_ratio = layout_unclip_ratio\n\u001b[32m    111\u001b[39m \u001b[38;5;28mself\u001b[39m.layout_merge_bboxes_mode = layout_merge_bboxes_mode\n\u001b[32m--> \u001b[39m\u001b[32m112\u001b[39m \u001b[38;5;28mself\u001b[39m.pre_ops, \u001b[38;5;28mself\u001b[39m.infer, \u001b[38;5;28mself\u001b[39m.post_op = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_build\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ocr/lib/python3.12/site-packages/paddlex/inference/models/object_detection/predictor.py:143\u001b[39m, in \u001b[36mDetPredictor._build\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    140\u001b[39m     pre_ops.insert(\u001b[32m1\u001b[39m, \u001b[38;5;28mself\u001b[39m.build_resize(\u001b[38;5;28mself\u001b[39m.img_size, \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[32m2\u001b[39m))\n\u001b[32m    142\u001b[39m \u001b[38;5;66;03m# build infer\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m143\u001b[39m infer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcreate_static_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    145\u001b[39m \u001b[38;5;66;03m# build postprocess op\u001b[39;00m\n\u001b[32m    146\u001b[39m post_op = \u001b[38;5;28mself\u001b[39m.build_postprocess()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ocr/lib/python3.12/site-packages/paddlex/inference/models/base/predictor/base_predictor.py:300\u001b[39m, in \u001b[36mBasePredictor.create_static_infer\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    298\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate_static_infer\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    299\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._use_hpip:\n\u001b[32m--> \u001b[39m\u001b[32m300\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPaddleInfer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    301\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mMODEL_FILE_PREFIX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pp_option\u001b[49m\n\u001b[32m    302\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    303\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    304\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m HPInfer(\n\u001b[32m    305\u001b[39m             \u001b[38;5;28mself\u001b[39m.model_dir,\n\u001b[32m    306\u001b[39m             \u001b[38;5;28mself\u001b[39m.MODEL_FILE_PREFIX,\n\u001b[32m    307\u001b[39m             \u001b[38;5;28mself\u001b[39m._hpi_config,\n\u001b[32m    308\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ocr/lib/python3.12/site-packages/paddlex/inference/models/common/static_infer.py:284\u001b[39m, in \u001b[36mPaddleInfer.__init__\u001b[39m\u001b[34m(self, model_name, model_dir, model_file_prefix, option)\u001b[39m\n\u001b[32m    282\u001b[39m \u001b[38;5;28mself\u001b[39m.model_file_prefix = model_file_prefix\n\u001b[32m    283\u001b[39m \u001b[38;5;28mself\u001b[39m._option = option\n\u001b[32m--> \u001b[39m\u001b[32m284\u001b[39m \u001b[38;5;28mself\u001b[39m.predictor = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    285\u001b[39m \u001b[38;5;28mself\u001b[39m.infer = PaddleInferChainLegacy(\u001b[38;5;28mself\u001b[39m.predictor)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ocr/lib/python3.12/site-packages/paddlex/inference/models/common/static_infer.py:483\u001b[39m, in \u001b[36mPaddleInfer._create\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    480\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m DEBUG:\n\u001b[32m    481\u001b[39m     config.disable_glog_info()\n\u001b[32m--> \u001b[39m\u001b[32m483\u001b[39m predictor = \u001b[43mpaddle\u001b[49m\u001b[43m.\u001b[49m\u001b[43minference\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_predictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m predictor\n",
      "\u001b[31mRuntimeError\u001b[39m: Unsupported GPU architecture"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from paddleocr import PaddleOCRVL\n",
    "\n",
    "# 配置项，可以根据需要改\n",
    "DEVICE = \"gpu:0\"   # 如果没有 GPU，就改成 \"cpu\"\n",
    "USE_LAYOUT_DETECTION = True      # 是否启用版面检测\n",
    "FORMAT_BLOCK_CONTENT = True      # 是否格式化 block_content 为 Markdown\n",
    "\n",
    "# 创建一个全局的 pipeline，后面直接拿来用\n",
    "pipeline = PaddleOCRVL(\n",
    "    device=DEVICE,\n",
    "    use_layout_detection=USE_LAYOUT_DETECTION,\n",
    "    format_block_content=FORMAT_BLOCK_CONTENT,\n",
    ")\n",
    "\n",
    "print(\"PaddleOCR-VL 初始化完成\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8281af6f-82e0-48ec-9201-8bfa43d0d543",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def parse_image_with_vl(\n",
    "    image_path: str,\n",
    "    out_dir: str = \"./output\",\n",
    "    save_files: bool = True,\n",
    "):\n",
    "    \"\"\"\n",
    "    使用全局 pipeline 解析一张图片（PNG/JPG 等），并返回解析结果对象列表。\n",
    "\n",
    "    参数：\n",
    "        image_path: 图片路径\n",
    "        out_dir: 结果保存目录\n",
    "        save_files: 是否把 JSON/Markdown/可视化图保存到磁盘\n",
    "\n",
    "    返回：\n",
    "        outputs: List[Result]，每个 Result 对象包含 .json / .markdown 等字段\n",
    "    \"\"\"\n",
    "    img_path = Path(image_path)\n",
    "    if not img_path.is_file():\n",
    "        raise FileNotFoundError(f\"Image not found: {img_path}\")\n",
    "\n",
    "    out_dir = Path(out_dir)\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # 1. 调用 VL 模型进行解析\n",
    "    outputs = pipeline.predict(input=str(img_path))\n",
    "\n",
    "    # 2. 一般一张 PNG 只对应一个 result，这里还是按 list 处理\n",
    "    for idx, res in enumerate(outputs):\n",
    "        print(f\"\\n===== Image #{idx} 解析结果（简要打印） =====\")\n",
    "        # 打印成 JSON 风格，方便在 Notebook 中折叠查看\n",
    "        res.print(format_json=True, indent=2, ensure_ascii=False)\n",
    "\n",
    "        if save_files:\n",
    "            # 2.1 保存 JSON\n",
    "            res.save_to_json(save_path=str(out_dir))\n",
    "\n",
    "            # 2.2 保存 Markdown\n",
    "            res.save_to_markdown(save_path=str(out_dir))\n",
    "\n",
    "            # 2.3 保存可视化图片（有版面框、表格框等）\n",
    "            res.save_to_img(save_path=str(out_dir))\n",
    "\n",
    "            # 2.4 额外再写一个“阅读顺序纯文本”文件，方便快速看内容\n",
    "            json_res = res.json  # dict\n",
    "            parsing_res_list = json_res.get(\"parsing_res_list\", [])\n",
    "            ordered_texts = []\n",
    "            for block in parsing_res_list:\n",
    "                label = block.get(\"block_label\", \"\")\n",
    "                content = block.get(\"block_content\", \"\")\n",
    "                if label == \"text\" and content:\n",
    "                    ordered_texts.append(content)\n",
    "\n",
    "            plain_text_path = out_dir / f\"{img_path.stem}_plain.txt\"\n",
    "            with plain_text_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "                for t in ordered_texts:\n",
    "                    f.write(t)\n",
    "                    f.write(\"\\n\\n\")\n",
    "\n",
    "            print(f\"\\n文件已保存到：{out_dir.resolve()}\")\n",
    "            print(f\"- JSON: {img_path.stem}_res.json\")\n",
    "            print(f\"- Markdown: {img_path.stem}.md\")\n",
    "            print(f(\"- 纯文本: {img_path.stem}_plain.txt\"))\n",
    "\n",
    "    return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baedeb2b-dd3f-400f-ba04-76cbce432489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把这里换成你自己的 png 路径\n",
    "test_image = \"./demo.png\"   # 例如：./data/page1.png\n",
    "\n",
    "results = parse_image_with_vl(\n",
    "    image_path=test_image,\n",
    "    out_dir=\"./vl_output\",\n",
    "    save_files=True,   # 如果只在 notebook 看结果，可以设成 False\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ocr_env",
   "language": "python",
   "name": "ocr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
